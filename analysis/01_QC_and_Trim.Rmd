
---
title: "Quality Control"
author: "Mark Watson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
    code_folding: show
    theme: spacelab
    highlight: pygments
    keep_md: no
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  keep_md: true  
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "BIOMI4300_Project/figures/01_QualityTrimming/") # send any figure output to this folder 
```

# Goals of this file 

1. Use raw fastq files and generate quality plots to assess quality of reads.
2. Filter and trim out bad sequences and bases from our sequencing files. 
3. Write out fastq files with high quality sequences. 
4. Evaluate the quality from our filter and trim. 
5. Infer Errors on forward and reverse reads individually.
6. Identified ASVs on forward and reverse reads separately, using the error model.  
7. Merge forward and reverse ASVs into "contiguous ASVs".  
8. Generate the ASV count table. (`otu_table` input for phyloseq.). 


Output that we will create in this file: 

1. Quality plots to asses pre- and post-quality trimming. 
2. Written files that include the filtered and trimmed data. (Note that this will be written during the `filterAndTrim()` function.)


# Setting up the environment

### Set the seed 

```{r set-seed}
# Any number can be chosen 
set.seed(238428)
```

### Timing of Script
```{r rmd-start}
# What time did we start running this script? 
start_time <- Sys.time()
start_time
```

# Load Libraries 
```{r load-libraries}
# Efficient package loading with pacman 
pacman::p_load(tidyverse, dada2, phyloseq, patchwork, DT, devtools, install = FALSE)
```

# Reading Raw Sequencing Files 
```{r load-data}
# Set the raw fastq path to the raw sequencing files 
# Path to the fastq files 
raw_fastqs_path <- "BIOMI4300_Project/data/rawfastqs/"
raw_fastqs_path
dir.exists(raw_fastqs_path)

# What files are in this path? Intuition Check 
head(list.files(raw_fastqs_path))

# How many files are there? 
length(list.files(raw_fastqs_path))

# Create vector of forward reads
forward_reads <- list.files(raw_fastqs_path, pattern = "_1.fastq.gz", full.names = TRUE)  

# Intuition Checks 
head(forward_reads)
# Intuition check #2: We should have fewer reads in the forward vector than in total 
stopifnot(length(forward_reads) < length(list.files(raw_fastqs_path)))

# Create a vector of reverse reads 
reverse_reads <- list.files(raw_fastqs_path, pattern = "_2.fastq.gz", full.names = TRUE)

# Intuition Checks
head(reverse_reads)
# Intuition check #2: Need to have equal number of forward and reverse files 
stopifnot(length(reverse_reads) == length(forward_reads))
```

# Assess Raw Read Quality 

## Evaluate raw sequence quality 

Let's see the quality of the raw reads *before* we trim

## Plot 12 random samples of plots 
```{r raw-quality-plot, fig.width=12, fig.height=8}
# Randomly select 12 samples from dataset to evaluate 
# Selecting 12 is typically better than 2 (like we did in class for efficiency)
random_samples <- sample(1:length(reverse_reads), size = 12)
random_samples

# Calculate and plot quality of these two samples
forward_filteredQual_plot_12 <- plotQualityProfile(forward_reads[random_samples]) + 
  labs(title = "Forward Read: Raw Quality")

reverse_filteredQual_plot_12 <- plotQualityProfile(reverse_reads[random_samples]) + 
  labs(title = "Reverse Read: Raw Quality")

# Plot them together with patchwork
forward_filteredQual_plot_12 + reverse_filteredQual_plot_12
```

---
## Aggregated Raw Quality Plots 

Next, we will plot all of the samples aggregated into one forward (left) and one reverse read (right) plot. 


```{r raw-aggregate-plot, fig.width=5.5, fig.height=3.5}
# Aggregate all QC plots 
# Forward reads
forward_preQC_plot <- 
  plotQualityProfile(forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Pre-QC")

# reverse reads
reverse_preQC_plot <- 
  plotQualityProfile(reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Pre-QC")

# Now, let's put the two plots together
preQC_aggregate_plot <- 
  # Plot the forward and reverse together 
  forward_preQC_plot + reverse_preQC_plot
# Show the plot
preQC_aggregate_plot
```

####  Prepare a placeholder for filtered reads 

```{r prep-filtered-sequences}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)

# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "BIOMI4300_Project/data/filtered_fastqs"

# Intuition Check 
filtered_fastqs_path

# create 2 vectors: filtered_forward_reads & filtered_reverse_reads
filtered_forward_reads <- 
  file.path(filtered_fastqs_path, paste0(sample_names, "_R1_filtered.fastq.gz"))

# Intuition Check 
length(filtered_forward_reads)

# reverse reads
filtered_reverse_reads <- 
  file.path(filtered_fastqs_path, paste0(sample_names, "_R2_filtered.fastq.gz"))

# Intuition Check 
head(filtered_reverse_reads)
```

# Filter and Trim Reads

Parameters of filter and trim **DEPEND ON THE DATASET AND SEQUENCING RUN**. If your sequences are run on multiple sequencing runs, you will need to run these separately!!! I recommended making parallel processes (either in separate files or back-to-back in a single file for each sequencing run). 

Some things to keep in mind are:

- The library preparation: *Are the primers included in the sequence? If so, they need to be trimmed out in this step*.  
- What do the above quality profiles of the reads look like? *If they are lower quality, it is highly recommended to use `maxEE = c(1,1)`.*  
- Do the reads dip suddenly in their quality? If so, explore `trimLeft` and `truncLen`
- Check out more of the parameters using `?filterAndTrim` to bring up the help page and do some googling about it. 

Some notes on two examples are below, with a description of a few of the parameters:

2. **Lower quality datasets** However, if the sequence quality was lower, it's recommended to use `maxEE = c(1,1)` as is in 
Important parameters in `filterAndTrim()` to be aware of:

- `maxEE` is a quality filtering threshold applied to expected errors. Here, if there's 2 expected errors. It's ok. But more than 2. Throw away the sequence. Two values, first is for forward reads; second is for reverse reads. If your read quality is generally lower than this dataset, I recommended you use `maxEE = c(1,1)`.  
- `trimLeft` can be used to remove the beginning bases of a read (e.g. to trim out primers!) 
- `truncLen` can be used to trim your sequences after a specific base pair when the quality gets lower. Though, please note that **this will shorten the ASVs**! For example, this can be used when the quality of the sequence suddenly gets lower, or clearly is typically lower. So, if the quality of the read drops below a phred score of 25 (on the y-axis of the plotQualityProfile above, which indicates ~99.5% confidence per base).  
- `maxN` the number of N bases. Here, using ASVs, we should ALWAYS remove all Ns from the data.  

```{r filter-and-trim}
# Assign and write out filtered fastq files 
# Here, in this class dataset, the Kozich et al.(2013) AEM
      # Link to paper: https://doi.org/10.1128/AEM.01043-13
# Therefore, we do not need to trim the primers, because they were not sequenced
filtered_reads <- 
  filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(1,1), 
              # Remove the first 8 bases at the beginning of the forward read
              trimLeft = 8,
              # Keep the full forward & trim final 2 bases in the reverse with truncLen
              truncLen = c(250, 248), 
              truncQ = 2, rm.phix = TRUE, compress = TRUE, 
              # Please set threads to be 8-10 (we want to respect others using the server!)
              # Note that if TRUE, it will use ALL threads (making it hard for others to use the server)
              multithread = 10) 

```

# Assess Trimmed Read Quality 

```{r filterTrim-quality-plots,  fig.width=12, fig.height=8}
# Plot the 12 random samples after QC
forward_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_forward_reads[random_samples]) + 
  labs(title = "Trimmed Forward Read Quality")

reverse_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_reverse_reads[random_samples]) + 
  labs(title = "Trimmed Reverse Read Quality")

# Put the two plots together 
forward_filteredQual_plot_12 + reverse_filteredQual_plot_12
```

## Aggregated Trimmed Plots 
```{r qc-aggregate-plot, fig.width=5.5, fig.height=3.5}
# Aggregate all QC plots 
# Forward reads
forward_postQC_plot <- 
  plotQualityProfile(filtered_forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Post-QC")

# reverse reads
reverse_postQC_plot <- 
  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Post-QC")

# Now, let's put the two plots together
postQC_aggregate_plot <- 
  # Plot the forward and reverse together 
  forward_postQC_plot + reverse_postQC_plot
# Show the plot
postQC_aggregate_plot
```

This post-QC quality score plot from 96 aggregated Illumina sequencing files shows the forward (left) and reverse (right) reads after quality filtering and trimming.

- *Forward Reads Post-QC*
  - High-quality (Q30+) bases throughout most of the read length.
  - A slight decline after ~220-230 cycles but still largely above a Phred of 30.
- *Reverse Reads Post-QC*
  - Initial bases (~0-10 cycles) remain stable and high-quality (likely trimmed effectively).
  - Mid-read quality (~10-180 cycles) remains strong (Q30+)
  - A noticeable decline in quality after ~180 cycles, but significantly improved compared to pre-QC.

**Takeaway:** Quality filtering successfully retained high-quality bases while removing low-quality tails.

## Read Retention Post-QC

```{r filterTrim-stats, message = FALSE, fig.height = 2.5, fig.width=8}
# Make output into dataframe 
filtered_df <- as.data.frame(filtered_reads) %>%
  mutate(percent.retained = reads.out/reads.in)

# Intuition check
# Visualize it in table format 
DT::datatable(filtered_df)

# Let's calculate some statistics
read_stats_df <- 
  filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out)/median(reads.in)),
          max_percent_retained = max(reads.out/reads.in),
          min_percent_retained = min(reads.out/reads.in))

# Take a look at it!
read_stats_df

# Plot it 
numSeqs_QC_dotplot <-
  filtered_df %>%
  ggplot(aes(x = reads.in, y = reads.out)) + 
  geom_point(alpha = 0.5, size = 2) + 
  labs(x = "# of Raw Seqs", 
       y = "# of Seqs Retained") + 
  # Now let's add a 1:1 line for reference of keeping 100% of the reads
  geom_abline(slope=1, intercept = 0, color = "deeppink")

# Now, let's look at the number of reads retained in a histogram
numRetained_QC_histplot <- 
  filtered_df %>%
  ggplot(aes(x = reads.out)) + 
  geom_histogram() + 
  labs(x = "# of Seqs Retained", 
       y = "# of Samples") 

# Create a histogram of percent reads retained in a histogram
percSeqs_QC_histplot <- 
  filtered_df %>%
  ggplot(aes(x = percent.retained)) + 
  geom_histogram() + 
  labs(x = "% of Seqs Retained", 
       y = "# of Samples") + 
  # Set the scale to be between 0-1 (0-100%)
  scale_x_continuous(limits = c(0, 1))

# Now, let's put the plots together
numSeqs_QC_dotplot + numRetained_QC_histplot + percSeqs_QC_histplot + 
  plot_annotation(tag_levels = 'A')
```

This figure presents three panels showing how many sequences were retained after quality filtering and trimming in the DADA2 pipeline. Let’s break down each panel:

**Panel A: Scatter Plot of Raw vs. Retained Sequences:**  

- X-axis: Number of raw sequences before filtering.
- Y-axis: Number of sequences retained after filtering.
- Pink Line: The diagonal line represents perfect retention (i.e., no sequences lost).

*Interpretation of Panel A:*
- A large number of sequences were lost.
  - seen as all points lie away from the pink line


**Panel B: Histogram of the Number of Sequences Retained per Sample**  

- X-axis: Number of sequences retained per sample.
- Y-axis: Number of samples with that many retained sequences.

*Interpretation of Panel B*  
Despite the large loss in A, normally distributed seqs were retained. 


**Panel C: Histogram of Percent of Sequences Retained**  

- X-axis: Proportion (%) of sequences retained per sample.
- Y-axis: Number of samples at each proportion.

*Interpretation of Panel C*. 
Despite the large loss in A, normally distributed seqs were retained. 

- **Max % Retained** is `r read_stats_df$max_percent_retained` is fantastic while **min % retained is** `r read_stats_df$min_percent_retained` ok.
- A **median % retained ** of `r read_stats_df$median_percent_retained` is great! 


**Consider re-running your `filterAndTrim()` if:** 

- If important samples lost too many reads, consider relaxing `maxEE` (expected errors) or adjusting truncation lengths (`truncLen`).
- Low merging success later on in the DADA2 workflow (suggests too much length variation).
- Reverse read degradation still affects error modeling (trim further if needed).


### Visualize QC differences in plot 
```{r pre-post-QC-plot, fig.width=6, fig.height=5.5}
# Plot the pre and post together in one plot
preQC_aggregate_plot / postQC_aggregate_plot
```

**Quality Score Improvements**

- *Forward Reads (Pre vs. Post-QC)*
  - *Beginning of read*: Before QC had large dip at start which was solved by an 8 bp trim at the start. 
  - *Middle of read*: Before QC had a large range of quality scores which was solved by a quality score cutoff.
  - *End of read*: Before QC had a large drop in quality score after ~200 which was solved by having a quality score cutoff.
- *Reverse Reads (Pre vs. Post-QC)*
  - *Beginning of read*: Before QC had large dip at start which was solved by an 8 bp trim at the start. 
  - *Middle of read*: Before QC had a large range of quality scores which was solved by a quality score cutoff.
  - *End of read*: Before QC had a large drop in quality score after ~200 which was solved by having a quality score cutoff.

# Done with Analyses for now! :) 

# Check Render Time
```{r stop-time}
# Take the time now that we are at the end of the script
end_time <- Sys.time()
end_time 

# Echo the elapsed time
elapsed_time <- round((end_time - start_time), 3)
elapsed_time
```

# Session Information 
```{r session-info}
# Ensure reproducibility 
devtools::session_info()
```
