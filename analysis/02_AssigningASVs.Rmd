---
title: "Assigning ASVs with DADA2"
author: "Mark Watson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
    code_folding: show
    theme: spacelab
    highlight: pygments
    keep_md: no
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  keep_md: true  
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "BIOMI4300_Project/figures/01_QualityTrimming/") # send any figure output to this folder 
```
# Background
## Goals
1. Infer errors on F and R reads
2. Identify ASVs on F and R
3. Merge F andR
4. Generate ASV count table
5. Trim ASVs
6. Remove Chimeras
7. Assign Taxonomy w/ silva db
8. Write out files

## Input:
1. filtered fastq.gz files
2. Sample Name Vector

## Output
1. ASV count table
2. ASV fasta file
3. Tax table
4. Sample Info

# Setting up the Environment
## Set Seed
```{r set-seed}
set.seed(238428)
```

## Timing Script
```{r timing}
start_time <- Sys.time()
start_time

```

## Load Libraries
```{r load-libraries}
pacman::p_load(tidyverse, BiocManager, devtools, dada2, phyloseq, patchwork, DT, install = FALSE)

```

## Load in Filtered Fastqs
```{r load-fastqs}
# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "BIOMI4300_Project/data/filtered_fastqs/"

dir.exists(filtered_fastqs_path)

# Intuition Check 
filtered_fastqs_path

# create 2 vectors: filtered_forward_reads & filtered_reverse_reads
filtered_forward_reads <- 
  list.files(filtered_fastqs_path, pattern = "_R1_filtered.fastq.gz" ,
             full.names = TRUE)  

# Intuition Check 
length(filtered_forward_reads)

filtered_reverse_reads <- 
  list.files(filtered_fastqs_path, pattern = "_R2_filtered.fastq.gz" ,
             full.names = TRUE)  

# Intuition Check 
length(filtered_reverse_reads)
```

# Assign Sample Names
```{r assign-sample-names}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(filtered_forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)

```

# Learn the Errors
```{r learn-errors}
# Forward reads 
error_forward_reads <- 
  learnErrors(filtered_forward_reads, multithread = 20)

# Reverse reads 
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads, multithread = 20)
```

```{r plot-errors}
# Plot Forward  
forward_error_plot <- 
  plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Read Error Model")

# Plot reverse
reverse_error_plot <- 
  plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Read Error Model")

# Put the two plots together
forward_error_plot + reverse_error_plot
```

All errors and the error model seem to align with the black line mostly falling around the red line.  Will proceed with inferring ASVs. 

# Infer ASVs
```{r infer-asv}
# Infer ASVs on the forward sequences
dada_forward <- dada(filtered_forward_reads,
                     err = error_forward_reads, 
                     multithread = TRUE)

# Infer ASVs on the reverse sequences 
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads,
                     multithread = TRUE)

```

# Merge F and R ASVs

```{r merge-ASVs}
# merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filtered_forward_reads, 
                          dada_reverse, filtered_reverse_reads,
                          verbose = TRUE)

```

# Create Raw ASV Count Table
```{r count-table}
# Create the ASV Count Table 
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Write out the file to data
write.table(raw_ASV_table, file = "BIOMI4300_Project/data/raw_ASV_counts.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# Check the type and dimensions of the data
dim(raw_ASV_table)

```

# Assess ASV Quality
1. What is the total length of amplicons?
- 805 - 341 = 464
2. What is total length minus primers and minus trim step?
- 464 - 8 = 456
3. What is the overlap between F and R?
- 2x300 sequencing
- 300 - 49 = 251
- 300 - 55 = 245
- Overlap = 245/352 = 0.69

## ASV Length Stats
```{r ASV-stats}
# Calculate summary stats
maxLength_ASV <- max(nchar(getSequences(raw_ASV_table))) # Longest ASV?
minLength_ASV <- min(nchar(getSequences(raw_ASV_table))) # Shortest ASV?
meanLength_ASV <- mean(nchar(getSequences(raw_ASV_table))) # Mean ASV length?
medianLength_ASV <- median(nchar(getSequences(raw_ASV_table))) # Median ASV length?

# Create a table to Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table)))

# Inspect the distribution of sequence lengths of all ASVs in data set 
# AFTER TRIM
data.frame(Seq_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(title = "Raw distribution of ASV length",
       y = "Number of ASVs", x = "ASV Sequence Length (bps)")
```

## Trim ASV Lengths
We expect to have only 456 bp, but we have a few shorter sequences which can likely be thrown out. 

```{r trim-ASVs}
# TRIM THE ASVS
# Let's trim the ASVs to only be the right size, which is indeed 245! 

# We will allow for a few 
raw_ASV_table_trimmed <- raw_ASV_table[, nchar(colnames(raw_ASV_table)) %in% c(449, 450)]


# Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table_trimmed)))

# What proportion of total ASV sequences are left in the data? 
sum(raw_ASV_table_trimmed)/sum(raw_ASV_table)

# Inspect the distribution of sequence lengths of all ASVs in dataset 
# AFTER TRIM
data.frame(Seq_Length = nchar(getSequences(raw_ASV_table_trimmed))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(title = "Trimmed distribution of ASV length",
       y = "Number of ASVs", x = "ASV Sequence Length (bps)")

```

# Remove Chimeras
```{r remove-chimeras}
# Remove the chimeras in the raw ASV table
noChimeras_ASV_table <- removeBimeraDenovo(raw_ASV_table_trimmed, 
                                           method="consensus", 
                                           multithread=TRUE, verbose=TRUE)

# What proportion is left of the sequences? 
percRetained_chimerasTrimmed <- sum(noChimeras_ASV_table)/sum(raw_ASV_table_trimmed)
percRetained_chimerasRaw <-sum(noChimeras_ASV_table)/sum(raw_ASV_table)

# Plot it 
data.frame(Seq_Length_NoChim = nchar(getSequences(noChimeras_ASV_table))) %>%
  ggplot(aes(x = Seq_Length_NoChim )) + 
  geom_histogram()+ 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(title = "Trimmed + Chimera Removal distribution of ASV length",
       y = "Number of ASVs", x = "ASV Sequence Length (bps)")
```

# Track the read counts
```{r track-read-counts}
# A little function to identify number seqs 
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs 
track <- cbind(sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_ASVs, getN),
               rowSums(noChimeras_ASV_table))

head(track)

# Update column names to be more informative (most are missing at the moment!)
colnames(track) <- c("denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- sample_names

# Generate a dataframe to track the reads through our DADA2 pipeline
track_counts_df <- 
  track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var = "names")

# Visualize it in table format 
DT::datatable(track_counts_df)

# Plot it!
track_counts_df %>%
  pivot_longer(denoisedF:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  geom_line(aes(group = names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Filtering Step", y = "Number of Sequences") + 
  theme_bw()
```

# Assign Taxonomy
```{r assign-taxa}
# Classify the ASVs against a reference set using the RDP Naive Bayesian Classifier described by Wang et al., (2007) in AEM
taxa_train <- 
  assignTaxonomy(noChimeras_ASV_table, 
                 "/workdir/in_class_data/taxonomy/silva_nr99_v138.2_toGenus_trainset.fa.gz", 
                 multithread = 200)

# Add the genus/species information 
taxa_addSpecies <- 
  addSpecies(taxa_train, 
             "/workdir/in_class_data/taxonomy/silva_v138.2_assignSpecies.fa.gz")

# Inspect the taxonomy 
taxa_print <- taxa_addSpecies # Removing sequence rownames for display only
rownames(taxa_print) <- NULL
#View(taxa_print)
```

# Prepare and Export Data
## Finalize ASV Count Tables
```{r asv-tables}
# Give headers more manageable names
# First pull the ASV sequences
asv_seqs <- colnames(noChimeras_ASV_table)
asv_seqs[1:5]

# make headers for our ASV seq fasta file, which will be our asv names
asv_headers <- vector(dim(noChimeras_ASV_table)[2], mode = "character")
asv_headers[1:5]

# loop through vector and fill it in with ASV names 
for (i in 1:dim(noChimeras_ASV_table)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep = "_")
}

# intitution check
asv_headers[1:5]

##### Rename ASVs in table then write out our ASV fasta file! 
#View(noChimeras_ASV_table)
asv_tab <- t(noChimeras_ASV_table)
#View(asv_tab)

## Rename our asvs! 
row.names(asv_tab) <- sub(">", "", asv_headers)
asv_tab[1:5, 1:5]

```

## Finalize Taxonomy Tables
```{r tax-tables}
# Inspect the taxonomy table
#View(taxa_addSpecies)

##### Prepare tax table 
# Add the ASV sequences from the rownames to a column 
new_tax_tab <- 
  taxa_addSpecies%>%
  as.data.frame() %>%
  rownames_to_column(var = "ASVseqs") 
head(new_tax_tab)

# intution check 
stopifnot(new_tax_tab$ASVseqs == colnames(noChimeras_ASV_table))

# Now let's add the ASV names 
rownames(new_tax_tab) <- rownames(asv_tab)
head(new_tax_tab)

### Final prep of tax table. Add new column with ASV names 
asv_tax <- 
  new_tax_tab %>%
  # add rownames from count table for phyloseq handoff
  mutate(ASV = rownames(asv_tab)) %>%
  # Resort the columns with select
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

head(asv_tax)

# Intution check
stopifnot(asv_tax$ASV == rownames(asv_tax), rownames(asv_tax) == rownames(asv_tab))
```

## Write and Export Tables
```{r write-files}
# Write BOTH the modified and unmodified ASV tables to a file!
# Write count table with ASV numbered names (e.g. ASV_1, ASV_2, etc)
write.table(asv_tab, 
            file = "BIOMI4300_Project/data/ASV_counts.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# Write count table with ASV sequence names
write.table(noChimeras_ASV_table, 
            file = "BIOMI4300_Project/data/ASV_counts_withSeqNames.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# Write out the fasta file for reference later on for what seq matches what ASV
asv_fasta <- c(rbind(asv_headers, asv_seqs))
# Save to a file!
write(asv_fasta, "BIOMI4300_Project/data/ASVs.fasta")

# SECOND, let's save the taxonomy tables 
# Write the table 
write.table(asv_tax, 
            file = "BIOMI4300_Project/data/ASV_taxonomy.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# THIRD, let's save to a RData object 
# Each of these files will be used in the next step of our analysis!
# RData objects are for easy loading :) 
save(noChimeras_ASV_table, file = "BIOMI4300_Project/data/noChimeras_ASV_table.RData")
save(asv_tab, file = "BIOMI4300_Project/data/ASV_counts.RData")

# And save the track_counts_df a R object, which we will merge with metadata information in the next step of the analysis in nalysis/02_Taxonomic_Assignment. 
save(track_counts_df, file = "BIOMI4300_Project/data/track_read_counts.RData")
```
# Check Render Time
```{r render-time}
end_time <- Sys.time()
end_time 
```
# Session Info
```{r session-info}
# Ensure reproducibility 
devtools::session_info()
```